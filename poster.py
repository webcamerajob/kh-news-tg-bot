#!/usr/bin/env python3
# coding: utf-8

import os
import json
import argparse
import asyncio
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from io import BytesIO

import httpx
from httpx import HTTPStatusError, ReadTimeout, Timeout
from PIL import Image

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ posted.json ---
MAX_POSTED_RECORDS = 200 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ID –≤ posted.json
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)
MAX_RETRIES   = 3
RETRY_DELAY   = 5.0
DEFAULT_DELAY = 10.0

def escape_markdown(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –¥–ª—è MarkdownV2.
    """
    markdown_chars = r'\_*[]()~`>#+-=|{}.!'
    return re.sub(r'([%s])' % re.escape(markdown_chars), r'\\\1', text)


def chunk_text(text: str, size: int = 4096) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª–∏–Ω–æ–π <= size, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–±–∑–∞—Ü—ã.
    """
    norm = text.replace('\r\n', '\n')
    paras = [p for p in norm.split('\n\n') if p.strip()]
    chunks, curr = [], ""

    def split_long(p: str) -> List[str]:
        parts, sub = [], ""
        for w in p.split(" "):
            if len(sub) + len(w) + 1 > size:
                parts.append(sub)
                sub = w
            else:
                sub = (sub + " " + w).lstrip()
        if sub:
            parts.append(sub)
        return parts

    for p in paras:
        if len(p) > size:
            if curr:
                chunks.append(curr)
                curr = ""
            chunks.extend(split_long(p))
        else:
            if not curr:
                curr = p
            elif len(curr) + 2 + len(p) <= size:
                curr += "\n\n" + p
            else:
                chunks.append(curr)
                curr = p

    if curr:
        chunks.append(curr)
    return chunks


def apply_watermark(img_path: Path, scale: float = 0.45) -> bytes:
    """
    –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç watermark.png –≤ –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    base = Image.open(img_path).convert("RGBA")
    wm   = Image.open("watermark.png").convert("RGBA")
    filt = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS)
    ratio = base.width * scale / wm.width
    wm = wm.resize((int(wm.width * ratio), int(wm.height * ratio)), resample=filt)
    base.paste(wm, (base.width - wm.width, 0), wm)
    buf = BytesIO()
    base.convert("RGB").save(buf, "PNG")
    return buf.getvalue()


async def _post_with_retry(
    client: httpx.AsyncClient,
    method: str,
    url: str,
    data: Dict[str, Any],
    files: Optional[Dict[str, Any]] = None
) -> bool:
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)
            resp.raise_for_status()
            return True

        except ReadTimeout:
            logging.warning("‚è± Timeout %s/%s for %s", attempt, MAX_RETRIES, url)

        except HTTPStatusError as e:
            code = e.response.status_code
            text = e.response.text
            if code == 429:
                # Telegram –ø—Ä–∏—Å—ã–ª–∞–µ—Ç retry_after –≤ JSON-–ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö
                info = e.response.json().get("parameters", {})
                wait = info.get("retry_after", RETRY_DELAY)
                logging.warning("üê¢ Rate limited %s/%s: retry after %s seconds", attempt, MAX_RETRIES, wait)
                await asyncio.sleep(wait)
                continue
            if 400 <= code < 500:
                logging.error("‚ùå %s %s: %s", method, code, text)
                return False
            logging.warning("‚ö†Ô∏è %s %s, retry %s/%s", method, code, attempt, MAX_RETRIES)

        await asyncio.sleep(RETRY_DELAY)

    logging.error("‚ò†Ô∏è Failed %s after %s attempts", url, MAX_RETRIES)
    return False


async def send_media_group(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    images: List[Path]
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–ª—å–±–æ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏.
    –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ apply_watermark.
    """
    url   = f"https://api.telegram.org/bot{token}/sendMediaGroup"
    media = []
    files = {}

    for idx, img in enumerate(images):
        key = f"file{idx}"
        files[key] = (img.name, apply_watermark(img), "image/png")
        media.append({
            "type": "photo",
            "media": f"attach://{key}"
        })

    data = {
        "chat_id": chat_id,
        "media": json.dumps(media, ensure_ascii=False)
    }
    return await _post_with_retry(client, "POST", url, data, files)


async def send_message(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    text: str
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–∑–±–æ—Ä–æ–º MarkdownV2.
    """
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": escape_markdown(text),
        "parse_mode": "MarkdownV2"
    }
    return await _post_with_retry(client, "POST", url, data)


def validate_article(
    art: Dict[str, Any],
    article_dir: Path
) -> Optional[Tuple[str, Path, List[Path]]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç–∞—Ç—å–∏:
      - title ‚Üí caption
      - –Ω–∞–ª–∏—á–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞
      - —Å–±–æ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (caption, text_path, images).
    """
    aid      = art.get("id")
    title    = art.get("title", "").strip()
    txt_name = Path(art.get("text_file", "")).name
    imgs     = art.get("images", [])

    if not title:
        logging.error("Invalid title for %s", aid)
        return None

    text_path = article_dir / txt_name
    if not text_path.is_file():
        candidates = list(article_dir.glob("*.txt"))
        if not candidates:
            logging.error("No text file in %s for %s", article_dir, aid)
            return None
        text_path = candidates[0]

    valid_imgs: List[Path] = []
    for name in imgs:
        p = article_dir / Path(name).name
        if not p.is_file():
            p = article_dir / "images" / Path(name).name
        if p.is_file():
            valid_imgs.append(p)

    if not valid_imgs:
        imgs_dir = article_dir / "images"
        if imgs_dir.is_dir():
            valid_imgs = [
                p for p in imgs_dir.iterdir()
                if p.suffix.lower() in (".jpg", ".jpeg", ".png")
            ]
        if not valid_imgs:
            logging.error("No images in %s for %s", article_dir, aid)
            return None

    cap = title if len(title) <= 1024 else title[:1023] + "‚Ä¶"
    return cap, text_path, valid_imgs


def load_posted_ids(state_file: Path) -> Set[int]:
    """
    –ß–∏—Ç–∞–µ—Ç state-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç set –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
      - –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π –∏–ª–∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª
      - —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª [1,2,3]
      - —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ [{"id":1}, {"id":2}]
    """
    if not state_file.is_file():
        return set()

    text = state_file.read_text(encoding="utf-8").strip()
    if not text:
        return set()

    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        logging.warning("State file not JSON: %s", state_file)
        return set()

    if not isinstance(data, list):
        logging.warning("State file is not a list: %s", state_file)
        return set()

    ids: Set[int] = set()
    for item in data:
        if isinstance(item, dict) and "id" in item:
            try:
                ids.add(int(item["id"]))
            except (ValueError, TypeError):
                pass
        elif isinstance(item, (int, str)) and str(item).isdigit():
            ids.add(int(item))
    return ids


def save_posted_ids(all_ids_to_save: Set[int], state_file: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID —Å—Ç–∞—Ç–µ–π –≤ —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–∞–∫—Å–∏–º—É–º MAX_POSTED_RECORDS, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –≤ –Ω–∞—á–∞–ª–æ –∏ –≤—ã—Ç–µ—Å–Ω—è—è —Å—Ç–∞—Ä—ã–µ –≤ –∫–æ–Ω—Ü–µ.
    """
    state_file.parent.mkdir(parents=True, exist_ok=True) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–µ ID –∏–∑ —Ñ–∞–π–ª–∞ (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –∏ –∏–∑–±–µ–≥–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    current_ids_list: deque = deque()
    if state_file.exists():
        try:
            with state_file.open("r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ ID, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
                    for item in data:
                        if isinstance(item, dict) and "id" in item:
                            current_ids_list.append(item["id"])
                        elif isinstance(item, int):
                            current_ids_list.append(item)
                else:
                    logging.warning(f"State file {state_file} has unexpected format. Starting with fresh records.")
        except json.JSONDecodeError:
            logging.warning(f"State file {state_file} is corrupted. Starting with fresh records.")
        except Exception as e:
            logging.error(f"Error reading existing state file {state_file}: {e}. Starting with fresh records.")

    # 2. –°–æ–∑–¥–∞–µ–º Set –∏–∑ —Ç–µ–∫—É—â–∏—Ö ID –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    current_ids_set = set(current_ids_list)

    # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º –Ω–æ–≤—ã–µ ID —Å —Ç–µ–∫—É—â–∏–º–∏, –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–µ –≤ –Ω–∞—á–∞–ª–æ
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º deque –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –Ω–∞—á–∞–ª–æ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    temp_ids_deque = deque(maxlen=MAX_POSTED_RECORDS)

    # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ ID, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ —Ä–∞–Ω–µ–µ
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ ID –≤ —É–±—ã–≤–∞—é—â–µ–º –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ–±—ã –±–æ–ª–µ–µ –Ω–æ–≤—ã–µ ID (–µ—Å–ª–∏ –æ–Ω–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ)
    # –ø–æ–ø–∞–¥–∞–ª–∏ –≤ –Ω–∞—á–∞–ª–æ –æ—á–µ—Ä–µ–¥–∏ –ø–µ—Ä–≤—ã–º–∏, –µ—Å–ª–∏ –∏—Ö –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤ —Ç–µ–∫—É—â–µ–º –±–∞—Ç—á–µ.
    for aid in sorted(list(all_ids_to_save - current_ids_set), reverse=True):
        temp_ids_deque.appendleft(aid)

    # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ ID, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –≤ —Ñ–∞–π–ª–µ –∏ –Ω–µ –±—ã–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã
    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å—Ç–∞—Ä—ã–º ID –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω–∏ –±—ã–ª–∏ –≤ —Ñ–∞–π–ª–µ
    for aid in current_ids_list:
        if aid in all_ids_to_save: # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ ID –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –∏—Ç–æ–≥–æ–≤–æ–º —Å–ø–∏—Å–∫–µ (—Ç.–µ. –Ω–µ –æ—Ç–±—Ä–æ—à–µ–Ω)
            if aid not in temp_ids_deque: # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –Ω–æ–≤—ã–π ID —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å–æ —Å—Ç–∞—Ä—ã–º
                temp_ids_deque.append(aid)

    # temp_ids_deque –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–µ–∑–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–æ MAX_POSTED_RECORDS,
    # —É–¥–∞–ª—è—è —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–æ–Ω—Ü–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –≤ –Ω–∞—á–∞–ª–æ.

    # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ ID –≤ —Ñ–∞–π–ª
    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º deque –æ–±—Ä–∞—Ç–Ω–æ –≤ list –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        final_list_to_save = list(temp_ids_deque)
        with state_file.open("w", encoding="utf-8") as f:
            json.dump(final_list_to_save, f, ensure_ascii=False, indent=2)
        logging.info(f"Saved {len(final_list_to_save)} IDs to state file {state_file} (max {MAX_POSTED_RECORDS}).")
    except Exception as e:
        logging.error(f"Failed to save state file {state_file}: {e}")


async def main(parsed_dir: str, state_path: str, limit: Optional[int]):
    token       = os.getenv("TELEGRAM_TOKEN")
    chat_id     = os.getenv("TELEGRAM_CHANNEL")
    if not token or not chat_id:
        logging.error("TELEGRAM_TOKEN or TELEGRAM_CHANNEL not set")
        return

    delay       = float(os.getenv("POST_DELAY", DEFAULT_DELAY))
    parsed_root = Path(parsed_dir)
    state_file  = Path(state_path)

    if not parsed_root.is_dir():
        logging.error("Parsed directory %s does not exist", parsed_root)
        return

    # 1) –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID
    posted_ids_old = load_posted_ids(state_file)
    logging.info("Loaded %d published IDs", len(posted_ids_old))

    # 2) –°–±–æ—Ä –ø–∞–ø–æ–∫ —Å–æ —Å—Ç–∞—Ç—å—è–º–∏
    parsed: List[Tuple[Dict[str, Any], Path]] = []
    for d in sorted(parsed_root.iterdir()):
        meta = d / "meta.json"
        if d.is_dir() and meta.is_file():
            try:
                art = json.loads(meta.read_text(encoding="utf-8"))
                parsed.append((art, d))
            except Exception as e:
                logging.warning("Cannot load meta %s: %s", d.name, e)

    # 2.1) –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ —á—Ç–æ –ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å?
    new_candidates = [
        art.get("id") for art, _ in parsed
        if art.get("id") not in posted_ids_old
    ]
    if not new_candidates:
        logging.info("üîç No new articles to post (total known IDs: %d)", len(posted_ids_old))
        return

    client   = httpx.AsyncClient(timeout=HTTPX_TIMEOUT)
    sent     = 0
    new_ids: Set[int] = set()

    # 3) –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏
    for art, article_dir in parsed:
        aid = art.get("id")
        if aid in posted_ids_old:
            continue
        if limit and sent >= limit:
            break

        validated = validate_article(art, article_dir)
        if not validated:
            continue

        caption, text_path, images = validated

        # 3.1) –ê–ª—å–±–æ–º —Ñ–æ—Ç–æ –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏
        if not await send_media_group(client, token, chat_id, images):
            continue

        # 3.2) –ü–æ–¥–ø–∏—Å—å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
        # await send_message(client, token, chat_id, caption)

        # 3.3) –¢–µ–ª–æ —Å—Ç–∞—Ç—å–∏ –ø–æ —á–∞–Ω–∫–∞–º
        raw    = text_path.read_text(encoding="utf-8")
        chunks = chunk_text(raw)
        for part in chunks:
            await send_message(client, token, chat_id, part)

        new_ids.add(aid)
        sent += 1
        logging.info("‚úÖ Posted ID=%s", aid)
        await asyncio.sleep(delay)

    await client.aclose()

    # 4) –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ID
    all_ids = posted_ids_old.union(new_ids)
    save_posted_ids(all_ids, state_file)
    logging.info("State updated with %d total IDs", len(all_ids))
    logging.info("üì¢ Done: sent %d articles", sent)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Poster: –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –≤ Telegram"
    )
    parser.add_argument(
        "--parsed-dir",
        type=str,
        default="articles",
        help="–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏"
    )
    parser.add_argument(
        "--state-file",
        type=str,
        default="articles/posted.json",
        help="–ø—É—Ç—å –∫ state-—Ñ–∞–π–ª—É"
    )
    parser.add_argument(
        "-n", "--limit",
        type=int,
        default=None,
        help="–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"
    )

    args = parser.parse_args()
    asyncio.run(main(
        parsed_dir=args.parsed_dir,
        state_path=args.state_file,
        limit=args.limit
    ))
