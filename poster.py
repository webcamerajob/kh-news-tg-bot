import os
import json
import argparse
import asyncio
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from io import BytesIO
from collections import deque # deque –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –ø–æ–ª–µ–∑–µ–Ω, –Ω–æ –Ω–µ —Ç–∞–∫ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ

import httpx
from httpx import HTTPStatusError, ReadTimeout, Timeout
from PIL import Image

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–µ–π –≤ posted.json ---
# –ï—Å–ª–∏ –ø—Ä–∏ 200 –∑–∞–ø–∏—Å—è—Ö —Ö–æ—Ç–∏–º –æ—Å—Ç–∞–≤–∏—Ç—å 100, —Ç–æ –ª–∏–º–∏—Ç —Ö—Ä–∞–Ω–µ–Ω–∏—è = 100.
MAX_POSTED_RECORDS = 100
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)
MAX_RETRIES   = 3
RETRY_DELAY   = 5.0
DEFAULT_DELAY = 10.0

def escape_html(text: str) -> str:
    """
    –≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã HTML (<, >, &, ") –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram —Å parse_mode='HTML'.
    –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –¥–æ–ª–∂–µ–Ω –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∫ –°–´–†–û–ú–£ —Ç–µ–∫—Å—Ç—É, –∫–æ—Ç–æ—Ä—ã–π –ù–ï –Ø–í–õ–Ø–ï–¢–°–Ø HTML-—Ç–µ–≥–∞–º–∏.
    """
    text = text.replace("&", "&amp;")
    text = text.replace("<", "&lt;")
    text = text.replace(">", "&gt;")
    text = text.replace('"', "&quot;")
    return text

def chunk_text(text: str, size: int = 4096) -> List[str]:
    """
    –î–µ–ª–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª–∏–Ω–æ–π <= size, —Å–æ—Ö—Ä–∞–Ω—è—è –∞–±–∑–∞—Ü—ã.
    """
    norm = text.replace('\r\n', '\n')
    paras = [p for p in norm.split('\n\n') if p.strip()]
    chunks, curr = [], ""

    def split_long(p: str) -> List[str]:
        parts, sub = [], ""
        for w in p.split(" "):
            if len(sub) + len(w) + 1 > size:
                parts.append(sub)
                sub = w
            else:
                sub = (sub + " " + w).lstrip()
        if sub:
            parts.append(sub)
        return parts

    for p in paras:
        if len(p) > size:
            if curr:
                chunks.append(curr)
                curr = ""
            chunks.extend(split_long(p))
        else:
            if not curr:
                curr = p
            elif len(curr) + 2 + len(p) <= size:
                curr += "\n\n" + p
            else:
                chunks.append(curr)
                curr = p

    if curr:
        chunks.append(curr)
    return chunks


def apply_watermark(img_path: Path, scale: float = 0.45) -> bytes:
    """
    –ù–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç watermark.png –≤ –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –æ—Ç—Å—Ç—É–ø–æ–º.
    """
    try:
        base_img = Image.open(img_path).convert("RGBA")
        base_width, base_height = base_img.size

        script_dir = Path(__file__).parent
        watermark_path = script_dir / "watermark.png"
        if not watermark_path.exists():
            logging.warning("Watermark file not found at %s. Skipping watermark.", watermark_path)
            img_byte_arr = BytesIO()
            base_img.save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()

        watermark_img = Image.open(watermark_path).convert("RGBA")

        wm_width, wm_height = watermark_img.size
        new_wm_width = int(base_width * scale)
        new_wm_height = int(wm_height * (new_wm_width / wm_width))
        filt = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS)
        watermark_img = watermark_img.resize((new_wm_width, new_wm_height), resample=filt)

        overlay = Image.new("RGBA", base_img.size, (0, 0, 0, 0))

        padding = int(base_width * 0.02)
        position = (base_width - new_wm_width - padding, padding)
        overlay.paste(watermark_img, position, watermark_img)

        composite_img = Image.alpha_composite(base_img, overlay)

        img_byte_arr = BytesIO()
        composite_img.save(img_byte_arr, format='PNG')
        return img_byte_arr.getvalue()
    except Exception as e:
        logging.error(f"Failed to apply watermark to {img_path}: {e}")
        try:
            img_byte_arr = BytesIO()
            Image.open(img_path).save(img_byte_arr, format='PNG')
            return img_byte_arr.getvalue()
        except Exception as e_orig:
            logging.error(f"Failed to load original image {img_path} after watermark error: {e_orig}")
            return b""


async def _post_with_retry(
    client: httpx.AsyncClient,
    method: str,
    url: str,
    data: Dict[str, Any],
    files: Optional[Dict[str, Any]] = None
) -> bool:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç HTTP POST-–∑–∞–ø—Ä–æ—Å —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π 429 Too Many Requests.
    """
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)
            resp.raise_for_status()
            return True

        except ReadTimeout:
            logging.warning("‚è± Timeout %s/%s for %s", attempt, MAX_RETRIES, url)
        except HTTPStatusError as e:
            code = e.response.status_code
            text = e.response.text
            if code == 429:
                info = e.response.json().get("parameters", {})
                wait = info.get("retry_after", RETRY_DELAY)
                logging.warning("üê¢ Rate limited %s/%s: retry after %s seconds", attempt, MAX_RETRIES, wait)
                await asyncio.sleep(wait)
                continue
            if 400 <= code < 500:
                logging.error("‚ùå %s %s: %s", method, code, text)
                return False
            logging.warning("‚ö†Ô∏è %s %s, retry %s/%s", method, code, attempt, MAX_RETRIES)
        except httpx.RequestError as e:
            logging.warning(f"Request error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")
        except Exception as e:
            logging.error(f"An unexpected error occurred on attempt {attempt + 1}/{MAX_RETRIES}: {e}")

        await asyncio.sleep(RETRY_DELAY)

    logging.error("‚ò†Ô∏è Failed %s after %s attempts", url, MAX_RETRIES)
    return False


async def send_media_group(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    images: List[Path]
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–ª—å–±–æ–º —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –±–µ–∑ –ø–æ–¥–ø–∏—Å–∏ (–ø–æ–¥–ø–∏—Å—å –±—É–¥–µ—Ç –≤ –ø–µ—Ä–≤–æ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–º —á–∞–Ω–∫–µ).
    –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ apply_watermark.
    –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 10 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã Telegram.
    """
    url   = f"https://api.telegram.org/bot{token}/sendMediaGroup"
    media = []
    files = {}
    photo_count = 0

    if not images:
        logging.warning("No images provided for media group.")
        return False

    for idx, img_path in enumerate(images):
        if photo_count >= 10:
            logging.warning("Telegram media group limit (10 images) reached. Skipping remaining images.")
            break
        try:
            image_bytes = apply_watermark(img_path)
            if not image_bytes:
                logging.warning(f"Skipping image {img_path} due to empty bytes after watermark processing.")
                continue

            key = f"file{idx}"
            files[key] = (img_path.name, image_bytes, "image/png")

            media_item = {
                "type": "photo",
                "media": f"attach://{key}"
            }
            media.append(media_item)
            photo_count += 1
        except Exception as e:
            logging.error(f"Error processing image {img_path} for media group: {e}")

    if not media:
        logging.warning("No valid images to send in media group after processing.")
        return False

    data = {
        "chat_id": chat_id,
        "media": json.dumps(media, ensure_ascii=False)
    }
    return await _post_with_retry(client, "POST", url, data, files)


async def send_message(
    client: httpx.AsyncClient,
    token: str,
    chat_id: str,
    text: str,
    reply_markup: Optional[Dict[str, Any]] = None
) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–∑–±–æ—Ä–æ–º HTML.
    –¢–µ–∫—Å—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–π –≤ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–∂–µ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω –¥–ª—è HTML.
    –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–Ω–æ–ø–∫–∏ (inline keyboard).
    """
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {
        "chat_id": chat_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    if reply_markup:
        data["reply_markup"] = json.dumps(reply_markup, ensure_ascii=False)
    return await _post_with_retry(client, "POST", url, data)


def validate_article(
    art: Dict[str, Any],
    article_dir: Path
) -> Optional[Tuple[str, Path, List[Path], str]]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–∫–∏ —Å—Ç–∞—Ç—å–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç HTML-–æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –ø—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É,
    —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∏ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –Ω–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫.
    """
    aid      = art.get("id")
    title    = art.get("title", "").strip()
    txt_name = Path(art.get("text_file", "")).name if art.get("text_file") else None

    if not title:
        logging.error("Invalid title for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    text_path: Optional[Path] = None
    if txt_name:
        candidate_path = article_dir / txt_name
        if candidate_path.is_file():
            text_path = candidate_path
    
    if not text_path:
        if (article_dir / "content.ru.txt").is_file():
            text_path = article_dir / "content.ru.txt"
        elif (article_dir / "content.txt").is_file():
            text_path = article_dir / "content.txt"
        else:
            candidates = list(article_dir.glob("*.txt"))
            if candidates:
                text_path = candidates[0]

    if not text_path or not text_path.is_file():
        logging.error("No text file found for article in %s (ID: %s). Skipping.", article_dir, aid)
        return None

    valid_imgs: List[Path] = []
    for name in art.get("images", []):
        p = article_dir / Path(name).name
        if not p.is_file():
            p = article_dir / "images" / Path(name).name
        if p.is_file():
            valid_imgs.append(p)

    if not valid_imgs:
        imgs_dir = article_dir / "images"
        if imgs_dir.is_dir():
            valid_imgs = [
                p for p in imgs_dir.iterdir()
                if p.suffix.lower() in (".jpg", ".jpeg", ".png")
            ]

    html_title = f"<b>{escape_html(title)}</b>"
    
    return html_title, text_path, valid_imgs, title

def load_posted_ids(state_file: Path) -> Set[int]:
    """
    –ß–∏—Ç–∞–µ—Ç state-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç set –∏–∑ ID.
    –ü—Ä–æ—Å—Ç–æ —á–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª.
    """
    if not state_file.is_file():
        logging.info("–§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è %s –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä.", state_file)
        return set()
    try:
        content = state_file.read_text(encoding="utf-8").strip()
        if not content:
            return set()
            
        data = json.loads(content)
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ int, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞—è –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ
        return {int(item) for item in data if str(item).isdigit()}
        
    except (json.JSONDecodeError, ValueError) as e:
        logging.warning("–§–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è %s –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –∏–º–µ–µ—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: %s. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä.", state_file, e)
        return set()
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è {state_file}: {e}. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä.")
        return set()

def save_posted_ids(all_ids_to_save: Set[int], state_file: Path) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ID, –æ–±—Ä–µ–∑–∞—è –µ–≥–æ –¥–æ MAX_POSTED_RECORDS,
    —Å–æ—Ö—Ä–∞–Ω—è—è —Å–∞–º—ã–µ –±–æ–ª—å—à–∏–µ (–Ω–æ–≤–µ–π—à–∏–µ) ID.
    """
    state_file.parent.mkdir(parents=True, exist_ok=True)

    # --- –ù–ê–ß–ê–õ–û –ë–õ–û–ö–ê –û–¢–õ–ê–î–ö–ò ---
    print("--- DEBUG: Entering save_posted_ids ---")
    print(f"Total unique IDs received to save: {len(all_ids_to_save)}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ñ–∞–π–ª–∞, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å
    original_content_set = set()
    if state_file.is_file():
        try:
            original_content_set = set(json.loads(state_file.read_text(encoding="utf-8")))
        except:
            print("DEBUG: Could not read or parse original state file for comparison.")
    
    print(f"Original IDs in file: {len(original_content_set)}")
    
    newly_added_ids = all_ids_to_save - original_content_set
    print(f"DEBUG: IDs that should be new: {sorted(list(newly_added_ids))}")
    # --- –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –û–¢–õ–ê–î–ö–ò ---

    # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º set –≤ —Å–ø–∏—Å–æ–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    sorted_ids = sorted(list(all_ids_to_save))

    # 2. –û–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫, –µ—Å–ª–∏ –æ–Ω –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è –ü–û–°–õ–ï–î–ù–ò–ï —ç–ª–µ–º–µ–Ω—Ç—ã
    if len(sorted_ids) > MAX_POSTED_RECORDS:
        final_list_to_save = sorted_ids[-MAX_POSTED_RECORDS:]
        logging.info(
            "–û–±—Ä–µ–∑–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID —Å %d –¥–æ %d (—Å–æ—Ö—Ä–∞–Ω—è—è —Å–∞–º—ã–µ –Ω–æ–≤—ã–µ).",
            len(sorted_ids),
            MAX_POSTED_RECORDS
        )
    else:
        final_list_to_save = sorted_ids

    # --- –ù–ê–ß–ê–õ–û –ë–õ–û–ö–ê –û–¢–õ–ê–î–ö–ò ---
    print(f"DEBUG: Final list size to be saved: {len(final_list_to_save)}")
    print(f"DEBUG: First 5 IDs in final list: {final_list_to_save[:5]}")
    print(f"DEBUG: Last 5 IDs in final list: {final_list_to_save[-5:]}")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å —Ç–µ–º, —á—Ç–æ –±—ã–ª–æ –≤ —Ñ–∞–π–ª–µ
    if set(final_list_to_save) == original_content_set:
        print("DEBUG: CRITICAL! The final list of IDs is identical to the original file content. This is why it's unchanged.")
    else:
        print("DEBUG: The final list is different from the original. The file should be updated.")
    # --- –ö–û–ù–ï–¶ –ë–õ–û–ö–ê –û–¢–õ–ê–î–ö–ò ---
    
    try:
        with state_file.open("w", encoding="utf-8") as f:
            json.dump(final_list_to_save, f, ensure_ascii=False, indent=2)
        logging.info(
            "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ %d ID –≤ —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è %s.",
            len(final_list_to_save),
            state_file
        )
    except Exception as e:
        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª —Å–æ—Å—Ç–æ—è–Ω–∏—è {state_file}: {e}")
        
async def main(parsed_dir: str, state_path: str, limit: Optional[int]):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ—Å—Ç–µ—Ä–∞.
    """
    token       = os.getenv("TELEGRAM_TOKEN")
    chat_id     = os.getenv("TELEGRAM_CHANNEL")
    if not token or not chat_id:
        logging.error("TELEGRAM_TOKEN –∏–ª–∏ TELEGRAM_CHANNEL –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        return

    delay       = float(os.getenv("POST_DELAY", DEFAULT_DELAY))
    parsed_root = Path(parsed_dir)
    state_file  = Path(state_path)

    if not parsed_root.is_dir():
        logging.error("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è %s –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –í—ã—Ö–æ–¥.", parsed_root)
        return

    # 1) –ó–∞–≥—Ä—É–∑–∫–∞ —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID.
    # posted_ids_old —Ç–µ–ø–µ—Ä—å —è–≤–ª—è–µ—Ç—Å—è set'–æ–º, –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ –æ–±—Ä–µ–∑–∞–Ω –¥–æ MAX_POSTED_RECORDS.
    posted_ids_old = load_posted_ids(state_file)
    logging.info("–ó–∞–≥—Ä—É–∂–µ–Ω–æ %d —Ä–∞–Ω–µ–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö ID –∏–∑ %s (–∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–µ–∑–∫–∏).", len(posted_ids_old), state_file.name)

    # 2) –°–±–æ—Ä –ø–∞–ø–æ–∫ —Å–æ —Å—Ç–∞—Ç—å—è–º–∏ –∏ –∏—Ö –≤–∞–ª–∏–¥–∞—Ü–∏—è
    articles_to_post: List[Dict[str, Any]] = []
    for d in sorted(parsed_root.iterdir()):
        meta_file = d / "meta.json"
        if d.is_dir() and meta_file.is_file():
            try:
                art_meta = json.loads(meta_file.read_text(encoding="utf-8"))
                # –í–∞–∂–Ω–æ: –∑–¥–µ—Å—å posted_ids_old —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ "–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ" ID
                if art_meta.get("id") is not None and art_meta["id"] not in posted_ids_old:
                    validated_data = validate_article(art_meta, d)
                    if validated_data:
                        html_title, text_path, image_paths, original_plain_title = validated_data
                        validated_data_dict = {
                            "id": art_meta["id"],
                            "html_title": html_title,
                            "text_path": text_path,
                            "image_paths": image_paths,
                            "original_plain_title": original_plain_title
                        }
                        articles_to_post.append(validated_data_dict)
                    else:
                        logging.warning("–í–∞–ª–∏–¥–∞—Ü–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç—å–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name)
                elif art_meta.get("id") is not None:
                    logging.debug("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—É—é —Å—Ç–∞—Ç—å—é ID=%s.", art_meta["id"])
                else:
                    logging.warning("–°—Ç–∞—Ç—å—è –≤ %s –Ω–µ –∏–º–µ–µ—Ç ID –≤ meta.json. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name)
            except json.JSONDecodeError as e:
                logging.warning("–ù–µ —É–¥–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ —Ä–∞–∑–æ–±—Ä–∞—Ç—å meta.json –≤ %s: %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name, e)
            except Exception as e:
                logging.error("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏ %s: %s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.", d.name, e)
    
    articles_to_post.sort(key=lambda x: x["id"])

    if not articles_to_post:
        logging.info("üîç –ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –í—ã—Ö–æ–¥.")
        return

    logging.info("–ù–∞–π–¥–µ–Ω–æ %d –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏.", len(articles_to_post))

    client    = httpx.AsyncClient()
    sent      = 0
    new_ids: Set[int] = set() # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –¥–ª—è —Å–±–æ—Ä–∞ ID, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ

    # 3) –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏
    for article in articles_to_post:
        if limit is not None and sent >= limit:
            logging.info("–õ–∏–º–∏—Ç –ø–∞—á–∫–∏ –≤ %d –¥–æ—Å—Ç–∏–≥–Ω—É—Ç. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.", limit)
            break

        aid         = article["id"]
        html_title  = article["html_title"]
        text_path   = article["text_path"]
        image_paths = article["image_paths"]
        original_plain_title = article["original_plain_title"]

        logging.info("–ü–æ–ø—ã—Ç–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ID=%s", aid)
        
        posted_successfully = False
        try:
            if image_paths:
                if not await send_media_group(client, token, chat_id, image_paths):
                    logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—É –¥–ª—è ID=%s. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç.", aid)
            
            raw_text = text_path.read_text(encoding="utf-8")
            cleaned_raw_text = raw_text
            if original_plain_title:
                escaped_plain_title_for_regex = re.escape(original_plain_title)
                pattern = re.compile(rf"^{escaped_plain_title_for_regex}\s*", re.DOTALL | re.IGNORECASE)
                match = pattern.match(raw_text)
                if match:
                    cleaned_raw_text = raw_text[match.end():]
                else:
                    logging.warning(
                        f"–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ '{original_plain_title}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è ID={aid}. "
                        "–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ meta.json."
                    )
                    cleaned_raw_text = raw_text

            escaped_raw_text = escape_html(cleaned_raw_text)
            full_html_content = f"{html_title}\n\n{escaped_raw_text}"
            
            chunks = chunk_text(full_html_content)
            num_chunks = len(chunks)

            all_chunks_sent = True
            for i, part in enumerate(chunks):
                current_reply_markup = None
                if i == num_chunks - 1:
                    keyboard = {
                        "inline_keyboard": [
                            [
                                {"text": "–û–±–º–µ–Ω –≤–∞–ª—é—Ç", "url": "https://t.me/mister1dollar"},
                                {"text": "–û—Ç–∑—ã–≤—ã", "url": "https://t.me/feedback1dollar"}
                            ]
                        ]
                    }
                    current_reply_markup = keyboard

                if not await send_message(client, token, chat_id, part, reply_markup=current_reply_markup):
                    logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π —á–∞–Ω–∫ –¥–ª—è ID=%s. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —á–∞–Ω–∫–∏ –∏ —Å—Ç–∞—Ç—å—é.", aid)
                    all_chunks_sent = False
                    break
            
            if all_chunks_sent:
                posted_successfully = True

        except Exception as e:
            logging.error(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏ ID={aid}: {e}. –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç–∞—Ç—å–µ.")
            posted_successfully = False

        if posted_successfully:
            new_ids.add(aid) # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–µ—Ç –Ω–æ–≤—ã—Ö ID, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ
            sent += 1
            logging.info("‚úÖ –û–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ ID=%s", aid)
        
        await asyncio.sleep(delay)

    await client.aclose()

    # 4) –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ ID
    # all_ids_to_save —Ç–µ–ø–µ—Ä—å –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ ID + –Ω–æ–≤—ã–µ ID
    all_ids_to_save = posted_ids_old.union(new_ids)
    save_posted_ids(all_ids_to_save, state_file)
    logging.info("–°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–æ. –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: %d.", len(all_ids_to_save))
    logging.info("üì¢ –ó–∞–≤–µ—Ä—à–µ–Ω–æ: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ %d —Å—Ç–∞—Ç–µ–π –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ.", sent)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Poster: –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—å–∏ –ø–∞–∫–µ—Ç–∞–º–∏ –≤ Telegram"
    )
    parser.add_argument(
        "--parsed-dir",
        type=str,
        default="articles",
        help="–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ —Å—Ç–∞—Ç—å—è–º–∏"
    )
    parser.add_argument(
        "--state-file",
        type=str,
        default="articles/posted.json",
        help="–ø—É—Ç—å –∫ state-—Ñ–∞–π–ª—É"
    )
    parser.add_argument(
        "-n", "--limit",
        type=int,
        default=None,
        help="–º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏"
    )
    args = parser.parse_args()
    asyncio.run(main(
        parsed_dir=args.parsed_dir,
        state_path=args.state_file,
        limit=args.limit
    ))
