import os

import json

import argparse

import asyncio

import logging

import re

from pathlib import Path

from typing import Any, Dict, List, Optional, Set, Tuple

from io import BytesIO

from collections import deque



import httpx

from httpx import HTTPStatusError, ReadTimeout, Timeout

from PIL import Image



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

logging.basicConfig(

Â  Â  level=logging.INFO,

Â  Â  format="%(asctime)s [%(levelname)s] %(message)s"

)

# --- ĞšĞ¾Ğ½ÑÑ‚Ğ°Ğ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ² posted.json ---

MAX_POSTED_RECORDS = 200 # ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ID Ğ² posted.json

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)

MAX_RETRIESÂ  Â = 3

RETRY_DELAYÂ  Â = 5.0

DEFAULT_DELAY = 10.0 # Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½ Ñ 5.0 Ğ½Ğ° 10.0, ĞºĞ°Ğº Ğ² Ğ²Ğ°ÑˆĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸





def escape_markdown(text: str) -> str:

Â  Â  """

Â  Â  Ğ­ĞºÑ€Ğ°Ğ½Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿ĞµÑ†ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ Ğ´Ğ»Ñ MarkdownV2.

Â  Â  """

Â  Â  markdown_chars = r'\_*[]()~`>#+-=|{}.!'

Â  Â  return re.sub(r'([%s])' % re.escape(markdown_chars), r'\\\1', text)





def chunk_text(text: str, size: int = 4096) -> List[str]:

Â  Â  """

Â  Â  Ğ”ĞµĞ»Ğ¸Ñ‚ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ´Ğ»Ğ¸Ğ½Ğ¾Ğ¹ <= size, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ğ°Ğ±Ğ·Ğ°Ñ†Ñ‹.

Â  Â  Ğ­Ğ¢Ğ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ Ğ’Ğ—Ğ¯Ğ¢Ğ Ğ˜Ğ— Ğ’ĞĞ¨Ğ•Ğ“Ğ ĞŸĞ Ğ•Ğ”ĞĞ¡Ğ¢ĞĞ’Ğ›Ğ•ĞĞĞĞ“Ğ ĞšĞĞ”Ğ, Ğ¢ĞĞš ĞšĞĞš ĞĞĞ Ğ‘ĞĞ›Ğ•Ğ• Ğ“Ğ˜Ğ‘ĞšĞĞ¯.

Â  Â  """

Â  Â  norm = text.replace('\r\n', '\n')

Â  Â  paras = [p for p in norm.split('\n\n') if p.strip()]

Â  Â  chunks, curr = [], ""



Â  Â  def split_long(p: str) -> List[str]:

Â  Â  Â  Â  parts, sub = [], ""

Â  Â  Â  Â  for w in p.split(" "):

Â  Â  Â  Â  Â  Â  if len(sub) + len(w) + 1 > size:

Â  Â  Â  Â  Â  Â  Â  Â  parts.append(sub)

Â  Â  Â  Â  Â  Â  Â  Â  sub = w

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  sub = (sub + " " + w).lstrip()

Â  Â  Â  Â  if sub:

Â  Â  Â  Â  Â  Â  parts.append(sub)

Â  Â  Â  Â  return parts



Â  Â  for p in paras:

Â  Â  Â  Â  if len(p) > size:

Â  Â  Â  Â  Â  Â  if curr:

Â  Â  Â  Â  Â  Â  Â  Â  chunks.append(curr)

Â  Â  Â  Â  Â  Â  Â  Â  curr = ""

Â  Â  Â  Â  Â  Â  chunks.extend(split_long(p))

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  if not curr:

Â  Â  Â  Â  Â  Â  Â  Â  curr = p

Â  Â  Â  Â  Â  Â  elif len(curr) + 2 + len(p) <= size:

Â  Â  Â  Â  Â  Â  Â  Â  curr += "\n\n" + p

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  chunks.append(curr)

Â  Â  Â  Â  Â  Â  Â  Â  curr = p



Â  Â  if curr:

Â  Â  Â  Â  chunks.append(curr)

Â  Â  return chunks





def apply_watermark(img_path: Path, scale: float = 0.45) -> bytes:

Â  Â  """

Â  Â  ĞĞ°ĞºĞ»Ğ°Ğ´Ñ‹Ğ²Ğ°ĞµÑ‚ watermark.png Ğ² Ğ¿Ñ€Ğ°Ğ²Ñ‹Ğ¹ Ğ²ĞµÑ€Ñ…Ğ½Ğ¸Ğ¹ ÑƒĞ³Ğ¾Ğ» Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ñ Ğ¾Ñ‚ÑÑ‚ÑƒĞ¿Ğ¾Ğ¼.

Â  Â  Ğ”ĞĞŸĞĞ›ĞĞ•ĞĞ˜Ğ¯: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ½Ğ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°ĞºĞ° Ğ¸ Ğ¾Ğ±Ñ‰Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº.

Â  Â  """

Â  Â  try:

Â  Â  Â  Â  base_img = Image.open(img_path).convert("RGBA")

Â  Â  Â  Â  base_width, base_height = base_img.size



Â  Â  Â  Â  script_dir = Path(__file__).parent

Â  Â  Â  Â  watermark_path = script_dir / "watermark.png"

Â  Â  Â  Â  if not watermark_path.exists():

Â  Â  Â  Â  Â  Â  logging.warning("Watermark file not found at %s. Skipping watermark.", watermark_path)

Â  Â  Â  Â  Â  Â  # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ», ĞµÑĞ»Ğ¸ Ğ½ĞµÑ‚ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ½Ğ°ĞºĞ°

Â  Â  Â  Â  Â  Â  img_byte_arr = BytesIO()

Â  Â  Â  Â  Â  Â  base_img.save(img_byte_arr, format='PNG')

Â  Â  Â  Â  Â  Â  return img_byte_arr.getvalue()



Â  Â  Â  Â  watermark_img = Image.open(watermark_path).convert("RGBA")



Â  Â  Â  Â  # Resize watermark

Â  Â  Â  Â  wm_width, wm_height = watermark_img.size

Â  Â  Â  Â  new_wm_width = int(base_width * scale)

Â  Â  Â  Â  new_wm_height = int(wm_height * (new_wm_width / wm_width))

Â  Â  Â  Â  filt = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS) # Ğ”Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ²ĞµÑ€ÑĞ¸Ğ¹ Pillow

Â  Â  Â  Â  watermark_img = watermark_img.resize((new_wm_width, new_wm_height), resample=filt)



Â  Â  Â  Â  # Create a transparent overlay

Â  Â  Â  Â  overlay = Image.new("RGBA", base_img.size, (0, 0, 0, 0))



Â  Â  Â  Â  # Position watermark (top-right, with some padding)

Â  Â  Â  Â  padding = int(base_width * 0.02) # 2% padding Ğ¾Ñ‚ Ğ²Ğ°ÑˆĞµĞ¹ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹ Ğ²ĞµÑ€ÑĞ¸Ğ¸

Â  Â  Â  Â  position = (base_width - new_wm_width - padding, padding)

Â  Â  Â  Â  overlay.paste(watermark_img, position, watermark_img)



Â  Â  Â  Â  # Composite the images Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ³Ğ¾ ÑĞ¼ĞµÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ñ

Â  Â  Â  Â  composite_img = Image.alpha_composite(base_img, overlay)



Â  Â  Â  Â  # Save to bytes

Â  Â  Â  Â  img_byte_arr = BytesIO()

Â  Â  Â  Â  composite_img.save(img_byte_arr, format='PNG') # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºĞ°Ğº PNG

Â  Â  Â  Â  return img_byte_arr.getvalue()

Â  Â  except Exception as e:

Â  Â  Â  Â  logging.error(f"Failed to apply watermark to {img_path}: {e}")

Â  Â  Â  Â  # Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  img_byte_arr = BytesIO()

Â  Â  Â  Â  Â  Â  Image.open(img_path).save(img_byte_arr, format='PNG')

Â  Â  Â  Â  Â  Â  return img_byte_arr.getvalue()

Â  Â  Â  Â  except Exception as e_orig:

Â  Â  Â  Â  Â  Â  logging.error(f"Failed to load original image {img_path} after watermark error: {e_orig}")

Â  Â  Â  Â  Â  Â  return b"" # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ Ğ±Ğ°Ğ¹Ñ‚Ñ‹, ĞµÑĞ»Ğ¸ Ğ´Ğ°Ğ¶Ğµ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ» Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ





async def _post_with_retry(

Â  Â  client: httpx.AsyncClient,

Â  Â  method: str,

Â  Â  url: str,

Â  Â  data: Dict[str, Any],

Â  Â  files: Optional[Dict[str, Any]] = None

) -> bool:

Â  Â  """

Â  Â  Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ HTTP POST-Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ°Ğ¼Ğ¸ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¾Ğ¹ 429 Too Many Requests.

Â  Â  Ğ’ĞĞ¨Ğ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜, ĞŸĞ Ğ˜ĞĞ¯Ğ¢Ğ ĞšĞĞš Ğ‘ĞĞ›Ğ•Ğ• Ğ“Ğ˜Ğ‘ĞšĞĞ¯ Ğ˜ Ğ¡ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğœ Ğ›ĞĞ“Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•Ğœ.

Â  Â  """

Â  Â  for attempt in range(1, MAX_RETRIES + 1):

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ data= Ğ¸ files= Ğ²Ğ¼ĞµÑÑ‚Ğ¾ json= Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ multipart/form-data

Â  Â  Â  Â  Â  Â  resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)

Â  Â  Â  Â  Â  Â  resp.raise_for_status()

Â  Â  Â  Â  Â  Â  return True



Â  Â  Â  Â  except ReadTimeout:

Â  Â  Â  Â  Â  Â  logging.warning("â± Timeout %s/%s for %s", attempt, MAX_RETRIES, url)



Â  Â  Â  Â  except HTTPStatusError as e:

Â  Â  Â  Â  Â  Â  code = e.response.status_code

Â  Â  Â  Â  Â  Â  text = e.response.text

Â  Â  Â  Â  Â  Â  if code == 429:

Â  Â  Â  Â  Â  Â  Â  Â  # Telegram Ğ¿Ñ€Ğ¸ÑÑ‹Ğ»Ğ°ĞµÑ‚ retry_after Ğ² JSON-Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ñ…

Â  Â  Â  Â  Â  Â  Â  Â  info = e.response.json().get("parameters", {})

Â  Â  Â  Â  Â  Â  Â  Â  wait = info.get("retry_after", RETRY_DELAY)

Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("ğŸ¢ Rate limited %s/%s: retry after %s seconds", attempt, MAX_RETRIES, wait)

Â  Â  Â  Â  Â  Â  Â  Â  await asyncio.sleep(wait)

Â  Â  Â  Â  Â  Â  Â  Â  continue # ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ¸ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ

Â  Â  Â  Â  Â  Â  if 400 <= code < 500:

Â  Â  Â  Â  Â  Â  Â  Â  logging.error("âŒ %s %s: %s", method, code, text)

Â  Â  Â  Â  Â  Â  Â  Â  return False # Ğ”Ğ»Ñ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ÑĞºĞ¸Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº Ğ½Ğµ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑĞµĞ¼

Â  Â  Â  Â  Â  Â  logging.warning("âš ï¸ %s %s, retry %s/%s", method, code, attempt, MAX_RETRIES)

Â  Â  Â  Â  except httpx.RequestError as e: # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… ÑĞµÑ‚ĞµĞ²Ñ‹Ñ… Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº httpx

Â  Â  Â  Â  Â  Â  logging.warning(f"Request error on attempt {attempt + 1}/{MAX_RETRIES}: {e}")

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  logging.error(f"An unexpected error occurred on attempt {attempt + 1}/{MAX_RETRIES}: {e}")



Â  Â  Â  Â  await asyncio.sleep(RETRY_DELAY)



Â  Â  logging.error("â˜ ï¸ Failed %s after %s attempts", url, MAX_RETRIES)

Â  Â  return False





async def send_media_group(

Â  Â  client: httpx.AsyncClient,

Â  Â  token: str,

Â  Â  chat_id: str,

Â  Â  images: List[Path]

) -> bool:

Â  Â  """

Â  Â  ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ°Ğ»ÑŒĞ±Ğ¾Ğ¼ Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ğ¹ Ğ±ĞµĞ· Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸.

Â  Â  Ğ’ÑĞµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ÑÑ‚ Ñ‡ĞµÑ€ĞµĞ· apply_watermark.

Â  Â  Ğ”ĞĞŸĞĞ›ĞĞ•ĞĞ˜Ğ¯: ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° 10 Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ğ°Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹ Telegram.

Â  Â  """

Â  Â  urlÂ  Â = f"https://api.telegram.org/bot{token}/sendMediaGroup"

Â  Â  media = []

Â  Â  files = {}

Â  Â  photo_count = 0



Â  Â  if not images:

Â  Â  Â  Â  logging.warning("No images provided for media group.")

Â  Â  Â  Â  return False



Â  Â  for idx, img_path in enumerate(images):

Â  Â  Â  Â  if photo_count >= 10: # Telegram limit for media groups

Â  Â  Â  Â  Â  Â  logging.warning("Telegram media group limit (10 images) reached. Skipping remaining images.")

Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  image_bytes = apply_watermark(img_path)

Â  Â  Â  Â  Â  Â  if not image_bytes:

Â  Â  Â  Â  Â  Â  Â  Â  logging.warning(f"Skipping image {img_path} due to empty bytes after watermark processing.")

Â  Â  Â  Â  Â  Â  Â  Â  continue



Â  Â  Â  Â  Â  Â  key = f"file{idx}"

Â  Â  Â  Â  Â  Â  files[key] = (img_path.name, image_bytes, "image/png") # img_path.name Ğ´Ğ»Ñ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°

Â  Â  Â  Â  Â  Â  media.append({

Â  Â  Â  Â  Â  Â  Â  Â  "type": "photo",

Â  Â  Â  Â  Â  Â  Â  Â  "media": f"attach://{key}"

Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  photo_count += 1

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  logging.error(f"Error processing image {img_path} for media group: {e}")

Â  Â  Â  Â  Â  Â  # ĞĞµ Ğ¿Ñ€ĞµĞºÑ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ, Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ



Â  Â  if not media:

Â  Â  Â  Â  logging.warning("No valid images to send in media group after processing.")

Â  Â  Â  Â  return False



Â  Â  data = {

Â  Â  Â  Â  "chat_id": chat_id,

Â  Â  Â  Â  "media": json.dumps(media, ensure_ascii=False)

Â  Â  }

Â  Â  return await _post_with_retry(client, "POST", url, data, files)





async def send_message(

Â  Â  client: httpx.AsyncClient,

Â  Â  token: str,

Â  Â  chat_id: str,

Â  Â  text: str

) -> bool:

Â  Â  """

Â  Â  ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ñ Ñ€Ğ°Ğ·Ğ±Ğ¾Ñ€Ğ¾Ğ¼ MarkdownV2.

Â  Â  """

Â  Â  url = f"https://api.telegram.org/bot{token}/sendMessage"

Â  Â  data = {

Â  Â  Â  Â  "chat_id": chat_id,

Â  Â  Â  Â  "text": escape_markdown(text),

Â  Â  Â  Â  "parse_mode": "MarkdownV2",

Â  Â  Â  Â  "disable_web_page_preview": True # ĞĞ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ñ‚ĞµĞ¹

Â  Â  }

Â  Â  return await _post_with_retry(client, "POST", url, data)





def validate_article(

Â  Â  art: Dict[str, Any],

Â  Â  article_dir: Path

) -> Optional[Tuple[str, Path, List[Path]]]:

Â  Â  """

Â  Â  ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿ĞºĞ¸ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ.

Â  Â  Ğ’ĞĞ¨Ğ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜, ĞŸĞ Ğ˜ĞĞ¯Ğ¢Ğ ĞšĞĞš Ğ‘ĞĞ›Ğ•Ğ• ĞĞĞ”Ğ•Ğ–ĞĞĞ¯.

Â  Â  """

Â  Â  aidÂ  Â  Â  = art.get("id")

Â  Â  titleÂ  Â  = art.get("title", "").strip()

Â  Â  txt_name = Path(art.get("text_file", "")).name if art.get("text_file") else None # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ° None

Â  Â  imgsÂ  Â  Â = art.get("images", [])



Â  Â  if not title:

Â  Â  Â  Â  logging.error("Invalid title for article in %s (ID: %s). Skipping.", article_dir, aid)

Â  Â  Â  Â  return None



Â  Â  # ĞŸĞ¾Ğ¸ÑĞº Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°

Â  Â  text_path: Optional[Path] = None

Â  Â  if txt_name:

Â  Â  Â  Â  candidate_path = article_dir / txt_name

Â  Â  Â  Â  if candidate_path.is_file():

Â  Â  Â  Â  Â  Â  text_path = candidate_path

Â  Â Â 

Â  Â  if not text_path: # Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ¾ text_file Ğ¸Ğ»Ğ¸ ĞµĞ³Ğ¾ Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾

Â  Â  Â  Â  # ĞŸÑ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ RU-Ñ„Ğ°Ğ¹Ğ»Ñƒ, Ğ·Ğ°Ñ‚ĞµĞ¼ EN, Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ»ÑĞ±Ğ¾Ğ¹ txt

Â  Â  Â  Â  if (article_dir / "content.ru.txt").is_file():

Â  Â  Â  Â  Â  Â  text_path = article_dir / "content.ru.txt"

Â  Â  Â  Â  elif (article_dir / "content.txt").is_file():

Â  Â  Â  Â  Â  Â  text_path = article_dir / "content.txt"

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  candidates = list(article_dir.glob("*.txt"))

Â  Â  Â  Â  Â  Â  if candidates:

Â  Â  Â  Â  Â  Â  Â  Â  text_path = candidates[0] # Ğ‘ĞµÑ€ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğ¹ txt



Â  Â  if not text_path or not text_path.is_file():

Â  Â  Â  Â  logging.error("No text file found for article in %s (ID: %s). Skipping.", article_dir, aid)

Â  Â  Â  Â  return None



Â  Â  # Ğ¡Ğ±Ğ¾Ñ€ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½Ğ¾Ğº

Â  Â  valid_imgs: List[Path] = []

Â  Â  # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿ÑƒÑ‚Ğ¸ Ğ¸Ğ· meta.json

Â  Â  for name in imgs:

Â  Â  Â  Â  p = article_dir / Path(name).name # ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ¸Ğ¼Ñ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ² images ÑÑÑ‹Ğ»Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ñ„Ğ°Ğ¹Ğ» Ğ² ĞºĞ¾Ñ€Ğ½Ğµ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸

Â  Â  Â  Â  if not p.is_file():

Â  Â  Â  Â  Â  Â  p = article_dir / "images" / Path(name).name # Ğ˜Ğ»Ğ¸ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ 'images'

Â  Â  Â  Â  if p.is_file():

Â  Â  Â  Â  Â  Â  valid_imgs.append(p)



Â  Â  # Ğ•ÑĞ»Ğ¸ Ğ¿Ğ¾ Ğ¿ÑƒÑ‚ÑĞ¼ Ğ¸Ğ· meta.json Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾, Ğ¸Ñ‰ĞµĞ¼ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ 'images'

Â  Â  if not valid_imgs:

Â  Â  Â  Â  imgs_dir = article_dir / "images"

Â  Â  Â  Â  if imgs_dir.is_dir():

Â  Â  Â  Â  Â  Â  valid_imgs = [

Â  Â  Â  Â  Â  Â  Â  Â  p for p in imgs_dir.iterdir()

Â  Â  Â  Â  Â  Â  Â  Â  if p.suffix.lower() in (".jpg", ".jpeg", ".png")

Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  # Ğ•ÑĞ»Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ²ÑĞµ ĞµÑ‰Ğµ Ğ½ĞµÑ‚, ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑŒÑ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹

Â  Â  Â  Â  # logging.warning("No images found for article in %s (ID: %s). Proceeding without images.", article_dir, aid)

Â  Â  Â  Â  # Ğ’ Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼ ÑĞ»ÑƒÑ‡Ğ°Ğµ, ĞµÑĞ»Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚, send_media_group Ğ²ĞµÑ€Ğ½ĞµÑ‚ False, Ğ¸ Ğ¼Ñ‹ Ğ¿ĞµÑ€ĞµĞ¹Ğ´ĞµĞ¼ Ğº Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ Ñ‚ĞµĞºÑÑ‚Ğ°.





Â  Â  # ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑÑŒ Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ğ°Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹/ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ (Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ 1024 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ° Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ¸Ğ°Ğ³Ñ€ÑƒĞ¿Ğ¿, Ğ´Ğ»Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ 4096)

Â  Â  # Ğ—Ğ´ĞµÑÑŒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ‰ĞµĞ¹ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¾Ğ¼

Â  Â  cap = title if len(title) <= 1024 else title[:1023] + "â€¦" # ĞĞ±Ñ€ĞµĞ·Ğ°ĞµĞ¼ Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾Ñ‚Ğ¾Ñ‡Ğ¸ĞµĞ¼ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğº Ğ¼ĞµĞ´Ğ¸Ğ°

Â  Â Â 

Â  Â  return cap, text_path, valid_imgs





def load_posted_ids(state_file: Path) -> Set[int]:

Â  Â  """

Â  Â  Ğ§Ğ¸Ñ‚Ğ°ĞµÑ‚ state-Ñ„Ğ°Ğ¹Ğ» Ğ¸ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ set Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ID.

Â  Â  ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚:

Â  Â  Â  - Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ Ğ¸Ğ»Ğ¸ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ»

Â  Â  Â  - ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‡Ğ¸ÑĞµĞ» [1,2,3]

Â  Â  Â  - ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ² [{"id":1}, {"id":2}]

Â  Â  Ğ’ĞĞ¨Ğ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜, ĞŸĞ Ğ˜ĞĞ¯Ğ¢Ğ ĞšĞĞš Ğ‘ĞĞ›Ğ•Ğ• ĞĞĞ”Ğ•Ğ–ĞĞĞ¯.

Â  Â  """

Â  Â  if not state_file.is_file():

Â  Â  Â  Â  logging.info("State file %s not found. Returning empty set.", state_file)

Â  Â  Â  Â  return set()



Â  Â  text = state_file.read_text(encoding="utf-8").strip()

Â  Â  if not text:

Â  Â  Â  Â  logging.warning("State file %s is empty. Returning empty set.", state_file)

Â  Â  Â  Â  return set()



Â  Â  try:

Â  Â  Â  Â  data = json.loads(text)

Â  Â  except json.JSONDecodeError:

Â  Â  Â  Â  logging.warning("State file %s is not valid JSON. Returning empty set.", state_file)

Â  Â  Â  Â  return set()



Â  Â  if not isinstance(data, list):

Â  Â  Â  Â  logging.warning("State file %s content is not a list. Returning empty set.", state_file)

Â  Â  Â  Â  return set()



Â  Â  ids: Set[int] = set()

Â  Â  for item in data:

Â  Â  Â  Â  if isinstance(item, dict) and "id" in item:

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  ids.add(int(item["id"]))

Â  Â  Â  Â  Â  Â  except (ValueError, TypeError):

Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("Invalid ID format in state file: %s. Skipping.", item)

Â  Â  Â  Â  Â  Â  Â  Â  pass

Â  Â  Â  Â  elif isinstance(item, (int, str)) and str(item).isdigit():

Â  Â  Â  Â  Â  Â  ids.add(int(item))

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  logging.warning("Unexpected item type in state file: %s. Skipping.", item)

Â  Â  return ids





def save_posted_ids(all_ids_to_save: Set[int], state_file: Path) -> None:

Â  Â  """

Â  Â  Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ID ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ² Ñ„Ğ°Ğ¹Ğ» ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ.

Â  Â  Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ MAX_POSTED_RECORDS, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¸ Ğ²Ñ‹Ñ‚ĞµÑĞ½ÑÑ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ² ĞºĞ¾Ğ½Ñ†Ğµ.

Â  Â  Ğ­Ğ¢Ğ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ ĞĞ¡Ğ¢ĞĞ•Ğ¢Ğ¡Ğ¯ ĞšĞĞš Ğ’ ĞŸĞ Ğ•Ğ”Ğ«Ğ”Ğ£Ğ©Ğ•Ğœ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ˜, ĞŸĞ›Ğ®Ğ¡ Ğ˜ĞœĞŸĞĞ Ğ¢ `deque`.

Â  Â  """

Â  Â  state_file.parent.mkdir(parents=True, exist_ok=True) # Ğ£Ğ±ĞµĞ´Ğ¸Ğ¼ÑÑ, Ñ‡Ñ‚Ğ¾ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚



Â  Â  # 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ ID Ğ¸Ğ· Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞ° Ğ¸ Ğ¸Ğ·Ğ±ĞµĞ³Ğ°Ğ½Ğ¸Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²)

Â  Â  current_ids_list: deque = deque()

Â  Â  if state_file.exists():

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  with state_file.open("r", encoding="utf-8") as f:

Â  Â  Â  Â  Â  Â  Â  Â  data = json.load(f)

Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(data, list):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ID, Ğ¸Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒÑ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ñ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ°Ğ¼Ğ¸

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for item in data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(item, dict) and "id" in item:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_ids_list.append(item["id"])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif isinstance(item, int):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  current_ids_list.append(item)

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.warning(f"State file {state_file} has unexpected format. Starting with fresh records.")

Â  Â  Â  Â  except json.JSONDecodeError:

Â  Â  Â  Â  Â  Â  logging.warning(f"State file {state_file} is corrupted. Starting with fresh records.")

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  logging.error(f"Error reading existing state file {state_file}: {e}. Starting with fresh records.")



Â  Â  # 2. Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Set Ğ¸Ğ· Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ñ… ID Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°

Â  Â  current_ids_set = set(current_ids_list)



Â  Â  # 3. ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ ID Ñ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¼Ğ¸, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾

Â  Â  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ deque Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¸ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ°

Â  Â  temp_ids_deque = deque(maxlen=MAX_POSTED_RECORDS)



Â  Â  # Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ ID, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¾ Ñ€Ğ°Ğ½ĞµĞµ

Â  Â  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ ID Ğ² ÑƒĞ±Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ±Ğ¾Ğ»ĞµĞµ Ğ½Ğ¾Ğ²Ñ‹Ğµ ID (ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ)

Â  Â  # Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°Ğ»Ğ¸ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¾Ñ‡ĞµÑ€ĞµĞ´Ğ¸ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸, ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ±Ñ‹Ğ»Ğ¾ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ğ±Ğ°Ñ‚Ñ‡Ğµ.

Â  Â  for aid in sorted(list(all_ids_to_save - current_ids_set), reverse=True):

Â  Â  Â  Â  temp_ids_deque.appendleft(aid)



Â  Â  # Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ ID, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ ÑƒĞ¶Ğµ Ğ±Ñ‹Ğ»Ğ¸ Ğ² Ñ„Ğ°Ğ¹Ğ»Ğµ Ğ¸ Ğ½Ğµ Ğ±Ñ‹Ğ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‡Ñ‚Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ñ‹

Â  Â  # ĞŸÑ€Ğ¾Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ğ¾ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¼ ID Ğ² Ñ‚Ğ¾Ğ¼ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¾Ğ½Ğ¸ Ğ±Ñ‹Ğ»Ğ¸ Ğ² Ñ„Ğ°Ğ¹Ğ»Ğµ

Â  Â  for aid in current_ids_list:

Â  Â  Â  Â  if aid in all_ids_to_save: # Ğ£Ğ±ĞµĞ´Ğ¸Ğ¼ÑÑ, Ñ‡Ñ‚Ğ¾ ID Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğ¼ ÑĞ¿Ğ¸ÑĞºĞµ (Ñ‚.Ğµ. Ğ½Ğµ Ğ¾Ñ‚Ğ±Ñ€Ğ¾ÑˆĞµĞ½)

Â  Â  Â  Â  Â  Â  if aid not in temp_ids_deque: # Ğ˜Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ, ĞµÑĞ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ID ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ ÑĞ¾ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¼

Â  Â  Â  Â  Â  Â  Â  Â  temp_ids_deque.append(aid)



Â  Â  # temp_ids_deque Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°ĞµÑ‚ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ğ´Ğ¾ MAX_POSTED_RECORDS,

Â  Â  # ÑƒĞ´Ğ°Ğ»ÑÑ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ñ ĞºĞ¾Ğ½Ñ†Ğ° Ğ¿Ñ€Ğ¸ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğ¸ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾.



Â  Â  # 4. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº ID Ğ² Ñ„Ğ°Ğ¹Ğ»

Â  Â  try:

Â  Â  Â  Â  # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ deque Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² list Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ

Â  Â  Â  Â  final_list_to_save = list(temp_ids_deque)

Â  Â  Â  Â  with state_file.open("w", encoding="utf-8") as f:

Â  Â  Â  Â  Â  Â  json.dump(final_list_to_save, f, ensure_ascii=False, indent=2)

Â  Â  Â  Â  logging.info(f"Saved {len(final_list_to_save)} IDs to state file {state_file} (max {MAX_POSTED_RECORDS}).")

Â  Â  except Exception as e:

Â  Â  Â  Â  logging.error(f"Failed to save state file {state_file}: {e}")





async def main(parsed_dir: str, state_path: str, limit: Optional[int]):

Â  Â  """

Â  Â  ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¿Ğ¾ÑÑ‚ĞµÑ€Ğ°.

Â  Â  ĞĞ‘ĞªĞ•Ğ”Ğ˜ĞĞ•ĞĞ˜Ğ• Ğ›ĞĞ“Ğ˜ĞšĞ˜ Ğ˜Ğ— Ğ’ĞĞ¨Ğ•Ğ™ Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ˜ Ğ˜ ĞŸĞ Ğ•Ğ”Ğ«Ğ”Ğ£Ğ©Ğ•Ğ“Ğ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ¯.

Â  Â  """

Â  Â  tokenÂ  Â  Â  Â = os.getenv("TELEGRAM_TOKEN")

Â  Â  chat_idÂ  Â  Â = os.getenv("TELEGRAM_CHANNEL")

Â  Â  if not token or not chat_id:

Â  Â  Â  Â  logging.error("TELEGRAM_TOKEN or TELEGRAM_CHANNEL environment variables must be set.")

Â  Â  Â  Â  return



Â  Â  delayÂ  Â  Â  Â = float(os.getenv("POST_DELAY", DEFAULT_DELAY))

Â  Â  parsed_root = Path(parsed_dir)

Â  Â  state_fileÂ  = Path(state_path)



Â  Â  if not parsed_root.is_dir():

Â  Â  Â  Â  logging.error("Parsed directory %s does not exist. Exiting.", parsed_root)

Â  Â  Â  Â  return



Â  Â  # 1) Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑƒĞ¶Ğµ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ID

Â  Â  posted_ids_old = load_posted_ids(state_file)

Â  Â  logging.info("Loaded %d previously posted IDs from %s.", len(posted_ids_old), state_file.name)



Â  Â  # 2) Ğ¡Ğ±Ğ¾Ñ€ Ğ¿Ğ°Ğ¿Ğ¾Ğº ÑĞ¾ ÑÑ‚Ğ°Ñ‚ÑŒÑĞ¼Ğ¸ Ğ¸ Ğ¸Ñ… Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ

Â  Â  articles_to_post: List[Dict[str, Any]] = []

Â  Â  for d in sorted(parsed_root.iterdir()): # Ğ˜Ñ‚ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ Ğ¿Ğ°Ğ¿ĞºĞ°Ğ¼

Â  Â  Â  Â  meta_file = d / "meta.json"

Â  Â  Â  Â  if d.is_dir() and meta_file.is_file():

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  art_meta = json.loads(meta_file.read_text(encoding="utf-8"))

Â  Â  Â  Â  Â  Â  Â  Â  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ID ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ ĞµÑ‰Ğµ Ğ½Ğµ Ğ±Ñ‹Ğ» Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½

Â  Â  Â  Â  Â  Â  Â  Â  if art_meta.get("id") is not None and art_meta["id"] not in posted_ids_old:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  validated_data = validate_article(art_meta, d)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if validated_data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ID Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‚ÑŒ ĞµĞ³Ğ¾ Ğ´Ğ°Ğ»ÑŒÑˆĞµ

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  validated_data_dict = {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "id": art_meta["id"],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "caption": validated_data[0],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "text_path": validated_data[1],

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "image_paths": validated_data[2]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  articles_to_post.append(validated_data_dict)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("Article metadata validation failed for %s. Skipping.", d.name)

Â  Â  Â  Â  Â  Â  Â  Â  elif art_meta.get("id") is not None:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.debug("Skipping already posted article ID=%s.", art_meta["id"])

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("Article in %s has no ID in meta.json. Skipping.", d.name)

Â  Â  Â  Â  Â  Â  except json.JSONDecodeError as e:

Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("Cannot load or parse meta.json in %s: %s. Skipping.", d.name, e)

Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  logging.error("An unexpected error occurred while processing article %s: %s. Skipping.", d.name, e)

Â  Â Â 

Â  Â  # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¿Ğ¾ ID Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸

Â  Â  # ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°ĞµĞ¼, Ñ‡Ñ‚Ğ¾ article["id"] ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ¼

Â  Â  articles_to_post.sort(key=lambda x: x["id"])



Â  Â  if not articles_to_post:

Â  Â  Â  Â  logging.info("ğŸ” No new articles to post. Exiting.")

Â  Â  Â  Â  return



Â  Â  logging.info("Found %d new articles to consider for posting.", len(articles_to_post))



Â  Â  clientÂ  Â  = httpx.AsyncClient()

Â  Â  sentÂ  Â  Â  = 0

Â  Â  new_ids: Set[int] = set() # ID, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ±Ñ‹Ğ»Ğ¸ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ñ‹ Ğ² Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ



Â  Â  # 3) ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸

Â  Â  for article in articles_to_post:

Â  Â  Â  Â  if limit is not None and sent >= limit:

Â  Â  Â  Â  Â  Â  logging.info("Batch limit of %d reached. Stopping.", limit)

Â  Â  Â  Â  Â  Â  break



Â  Â  Â  Â  aidÂ  Â  Â  Â = article["id"]

Â  Â  Â  Â  captionÂ  Â = article["caption"]

Â  Â  Â  Â  text_path = article["text_path"]

Â  Â  Â  Â  image_paths = article["image_paths"]



Â  Â  Â  Â  logging.info("Attempting to post ID=%s", aid)

Â  Â  Â  Â Â 

Â  Â  Â  Â  posted_successfully = False

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  # 3.1) ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ).

Â  Â  Â  Â  Â  Â  if image_paths:

Â  Â  Â  Â  Â  Â  Â  Â  if not await send_media_group(client, token, chat_id, image_paths):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.warning("Failed to send media group for ID=%s. Proceeding to send text only (title already in text).", aid)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ğ•ÑĞ»Ğ¸ Ğ¼ĞµĞ´Ğ¸Ğ°Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ğ½Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ°, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºÑƒ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ°.

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ€Ğ°Ğ·Ñƒ Ğº Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°.
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ğ•ÑĞ»Ğ¸ Ğ¼ĞµĞ´Ğ¸Ğ°Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ°, Ğ·Ğ´ĞµÑÑŒ ĞĞ• Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ´ĞµĞ»Ğ°ĞµĞ¼, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº Ğ½Ğµ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒÑÑ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pass
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  # Ğ•ÑĞ»Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½ĞµÑ‚ ÑĞ¾Ğ²ÑĞµĞ¼, ĞĞ• Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ.
Â  Â  Â  Â  Â  Â  Â  Â  logging.info("No images for ID=%s. Proceeding to send text only (title already in text).", aid)
Â  Â  Â  Â  Â  Â  Â  Â  # ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ€Ğ°Ğ·Ñƒ Ğº Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°.

Â  Â  Â  Â  Â  Â  # 3.2) Ğ¢ĞµĞ»Ğ¾ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¿Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ°Ğ¼
Â  Â  Â  Â  Â  Â  raw_text = text_path.read_text(encoding="utf-8")
Â  Â  Â  Â  Â  Â  chunks = chunk_text(raw_text)
Â  Â  Â  Â  Â  Â  all_chunks_sent = True
Â  Â  Â  Â  Â  Â  for part in chunks:
Â  Â  Â  Â  Â  Â  Â  Â  if not await send_message(client, token, chat_id, part):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  logging.error("Failed to send a text chunk for ID=%s. Skipping remaining chunks and article.", aid)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_chunks_sent = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  Â  Â  if all_chunks_sent:
Â  Â  Â  Â  Â  Â  Â  Â  posted_successfully = True

Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  logging.error(f"âŒ An error occurred during posting article ID={aid}: {e}. Moving to next article.")
Â  Â  Â  Â  Â  Â  posted_successfully = False # Ğ£Ğ±ĞµĞ´Ğ¸Ğ¼ÑÑ, Ñ‡Ñ‚Ğ¾ Ñ„Ğ»Ğ°Ğ³ ÑĞ±Ñ€Ğ¾ÑˆĞµĞ½ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ

Â  Â  Â  Â  if posted_successfully:
Â  Â  Â  Â  Â  Â  new_ids.add(aid) # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² Set Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ID
Â  Â  Â  Â  Â  Â  sent += 1
Â  Â  Â  Â  Â  Â  logging.info("âœ… Posted ID=%s", aid)
            
Â  Â  Â  Â  await asyncio.sleep(delay)
        
Â  Â  await client.aclose()

Â  Â  # 4) Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº ID
Â  Â  # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ID Ñ Ğ½Ğ¾Ğ²Ñ‹Ğ¼Ğ¸, ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ² ÑÑ‚Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ
Â  Â  all_ids_to_save = posted_ids_old.union(new_ids)
Â  Â  save_posted_ids(all_ids_to_save, state_file)
Â  Â  logging.info("State updated. Total unique IDs to be saved: %d.", len(all_ids_to_save))
Â  Â  logging.info("ğŸ“¢ Done: sent %d articles in this run.", sent)

if __name__ == "__main__"
Â  Â  parser = argparse.ArgumentParser(
Â  Â  Â  Â  description="Poster: Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ°Ğ¼Ğ¸ Ğ² Telegram"
Â  Â  )
Â  Â  parser.add_argument(
Â  Â  Â  Â  "--parsed-dir",
Â  Â  Â  Â  type=str,
Â  Â  Â  Â  default="articles",
Â  Â  Â  Â  help="Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ñ Ñ€Ğ°ÑĞ¿Ğ°Ñ€ÑĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒÑĞ¼Ğ¸"
Â  Â  )
Â  Â  parser.add_argument(
Â  Â  Â  Â  "--state-file",
Â  Â  Â  Â  type=str,
Â  Â  Â  Â  default="articles/posted.json",
Â  Â  Â  Â  help="Ğ¿ÑƒÑ‚ÑŒ Ğº state-Ñ„Ğ°Ğ¹Ğ»Ñƒ"
Â  Â  )
Â  Â  parser.add_argument(
Â  Â  Â  Â  "-n", "--limit",
Â  Â  Â  Â  type=int,
Â  Â  Â  Â  default=None,
Â  Â  Â  Â  help="Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ¸"
Â  Â  )

Â  Â  args = parser.parse_args()
Â  Â  # Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ•: ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° Ğ°Ñ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ Ğ² main, ĞºĞ°Ğº Ğ²Ñ‹ Ğ¸Ğ·Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾ Ñ…Ğ¾Ñ‚ĞµĞ»Ğ¸.
Â  Â  asyncio.run(main(
Â  Â  Â  Â  parsed_dir=args.parsed_dir,
Â  Â  Â  Â  state_path=args.state_file,
Â  Â  Â  Â  limit=args.limit
Â  Â  ))
