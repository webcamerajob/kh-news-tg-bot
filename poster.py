import os
import json
import argparse
import asyncio
import logging
import re
import subprocess
import time
import shutil
import fcntl
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from io import BytesIO
import httpx
from httpx import HTTPStatusError, ReadTimeout, Timeout
from PIL import Image

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
MAX_POSTED_RECORDS = 100
WATERMARK_SCALE = 0.35
HTTPX_TIMEOUT = Timeout(connect=10.0, read=60.0, write=10.0, pool=5.0)
MAX_RETRIES   = 3
RETRY_DELAY   = 5.0
DEFAULT_DELAY = 10.0

# --- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def escape_html(text: str) -> str:
    return text.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;")

def chunk_text(text: str, size: int = 4096) -> List[str]:
    paras = [p for p in text.replace('\r\n', '\n').split('\n\n') if p.strip()]
    chunks, current_chunk = [], ""
    for p in paras:
        if len(p) > size:
            if current_chunk: chunks.append(current_chunk)
            parts, sub_part = [], ""
            for word in p.split():
                if len(sub_part) + len(word) + 1 > size:
                    parts.append(sub_part)
                    sub_part = word
                else:
                    sub_part = f"{sub_part} {word}".lstrip()
            if sub_part: parts.append(sub_part)
            chunks.extend(parts)
            current_chunk = ""
        else:
            if not current_chunk: current_chunk = p
            elif len(current_chunk) + len(p) + 2 <= size: current_chunk += f"\n\n{p}"
            else:
                chunks.append(current_chunk)
                current_chunk = p
    if current_chunk: chunks.append(current_chunk)
    return chunks

# --- –ë–õ–û–ö –û–ë–†–ê–ë–û–¢–ö–ò –ú–ï–î–ò–ê ---

def apply_watermark(img_path: Path, scale: float) -> bytes:
    """–ù–∞–ª–æ–∂–µ–Ω–∏–µ –≤–æ–¥—è–Ω–æ–≥–æ –∑–Ω–∞–∫–∞ –Ω–∞ —Ñ–æ—Ç–æ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    try:
        base_img = Image.open(img_path).convert("RGBA")
        base_width, _ = base_img.size
        watermark_path = Path(__file__).parent / "watermark.png"
        
        if not watermark_path.exists():
            logging.warning(f"‚ö†Ô∏è –§–∞–π–ª –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. {img_path.name} –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –±–µ–∑ –Ω–µ—ë.")
            img_byte_arr = BytesIO()
            base_img.convert("RGB").save(img_byte_arr, format='JPEG', quality=90)
            return img_byte_arr.getvalue()

        watermark_img = Image.open(watermark_path).convert("RGBA")
        wm_width, wm_height = watermark_img.size
        
        # –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–æ–≤: 35% –æ—Ç —à–∏—Ä–∏–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª–∞
        new_wm_width = int(base_width * scale)
        new_wm_height = int(wm_height * (new_wm_width / wm_width))
        
        resample_filter = getattr(Image.Resampling, "LANCZOS", Image.LANCZOS)
        watermark_img = watermark_img.resize((new_wm_width, new_wm_height), resample=resample_filter)
        
        # –ü–æ–∑–∏—Ü–∏—è: –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª
        overlay = Image.new("RGBA", base_img.size, (0, 0, 0, 0))
        padding = 10 
        position = (base_width - new_wm_width - padding, padding)
        
        overlay.paste(watermark_img, position, watermark_img)
        composite_img = Image.alpha_composite(base_img, overlay).convert("RGB")
        
        img_byte_arr = BytesIO()
        composite_img.save(img_byte_arr, format='JPEG', quality=90)
        
        logging.info(f"üé® –í–æ—Ç–µ—Ä–º–∞—Ä–∫–∞ –Ω–∞–ª–æ–∂–µ–Ω–∞ –Ω–∞ —Ñ–æ—Ç–æ: {img_path.name}")
        return img_byte_arr.getvalue()
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ –¥–ª—è {img_path.name}: {e}")
        return img_path.read_bytes() if img_path.exists() else b""

async def process_video_logic(video_url: str, watermark_path: str = "watermark.png") -> Optional[str]:
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ 360p –∏ –Ω–∞–ª–æ–∂–µ–Ω–∏–µ –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∏ —Å –≤—ã–≤–æ–¥–æ–º –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ –≤ –ª–æ–≥"""
    if not video_url: return None
    ts = int(time.time())
    raw_path, final_path = f"raw_{ts}.mp4", f"video_{ts}.mp4"
    
    logging.info(f"üé¨ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {video_url}")
    
    async with httpx.AsyncClient(timeout=30) as client:
        try:
            # 1. –ó–∞–ø—Ä–æ—Å –∫ Loader.to
            resp = await client.get("https://loader.to/ajax/download.php", params={"format": "360", "url": video_url})
            task_id = resp.json().get("id")
            logging.info(f"‚è≥ –ó–∞–¥–∞—á–∞ Loader.to —Å–æ–∑–¥–∞–Ω–∞. ID: {task_id}")
            
            # 2. –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            download_url = None
            for attempt in range(25):
                await asyncio.sleep(3)
                status_resp = await client.get("https://loader.to/ajax/progress.php", params={"id": task_id})
                status = status_resp.json()
                
                prog_text = status.get('text', '–æ–±—Ä–∞–±–æ—Ç–∫–∞')
                logging.info(f"   [{attempt+1}/25] –°—Ç–∞—Ç—É—Å –≤–∏–¥–µ–æ: {prog_text}")
                
                if status.get("success") == 1:
                    download_url = status.get("download_url")
                    break
            
            if not download_url:
                logging.error("‚ùå Loader.to –Ω–µ –æ—Ç–¥–∞–ª —Å—Å—ã–ª–∫—É –∑–∞ –æ—Ç–≤–µ–¥–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è.")
                return None

            # 3. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
            logging.info(f"‚¨áÔ∏è –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ {raw_path}...")
            async with client.stream("GET", download_url) as r:
                with open(raw_path, 'wb') as f:
                    async for chunk in r.aiter_bytes(): f.write(chunk)

            # 4. FFmpeg –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∞
            logging.info("‚öôÔ∏è –ó–∞–ø—É—Å–∫ FFmpeg —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ (360p + –≤–æ—Ç–µ—Ä–º–∞—Ä–∫–∞ 35%)...")
            cmd = [
                "ffmpeg", "-y", "-i", raw_path, "-i", watermark_path,
                "-filter_complex", f"[1:v][0:v]scale2ref=iw*{WATERMARK_SCALE}:-1[wm][vid];[vid][wm]overlay=W-w-10:10",
                "-c:v", "libx264", "-preset", "ultrafast", "-crf", "28", "-c:a", "copy", final_path
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE
            )
            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                logging.error(f"‚ùå FFmpeg –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {stderr.decode()}")
                return None

            if os.path.exists(raw_path): os.remove(raw_path)
            logging.info(f"‚úÖ –í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {final_path}")
            return final_path
            
        except Exception as e:
            logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–∏–¥–µ–æ: {e}")
            if os.path.exists(raw_path): os.remove(raw_path)
            return None

# --- –°–ï–¢–ï–í–û–ô –ë–õ–û–ö ---

async def _post_with_retry(client: httpx.AsyncClient, method: str, url: str, data: Dict[str, Any], files: Optional[Dict[str, Any]] = None) -> bool:
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = await client.request(method, url, data=data, files=files, timeout=HTTPX_TIMEOUT)
            resp.raise_for_status()
            return True
        except HTTPStatusError as e:
            if e.response.status_code == 429:
                retry_after = int(e.response.json().get("parameters", {}).get("retry_after", RETRY_DELAY))
                await asyncio.sleep(retry_after)
            elif 400 <= e.response.status_code < 500: return False
            else: await asyncio.sleep(RETRY_DELAY * attempt)
        except Exception: await asyncio.sleep(RETRY_DELAY * attempt)
    return False

async def send_complex_media_group(client: httpx.AsyncClient, token: str, chat_id: str, images: List[Path], video_path: Optional[str], watermark_scale: float) -> bool:
    """–°–±–æ—Ä–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø. –í–∏–¥–µ–æ –í–°–ï–ì–î–ê –∏–¥–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–º –æ–±—ä–µ–∫—Ç–æ–º."""
    all_items = []
    files_to_send = {}
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–æ—Ç–æ
    logging.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(images)} —Ñ–æ—Ç–æ –¥–ª—è –∞–ª—å–±–æ–º–∞...")
    for idx, img_path in enumerate(images):
        image_bytes = apply_watermark(img_path, scale=watermark_scale)
        if image_bytes:
            key = f"photo_{idx}"
            files_to_send[key] = (img_path.name, image_bytes, "image/jpeg")
            all_items.append({"type": "photo", "media": f"attach://{key}"})
    
    # –í–∏–¥–µ–æ –≤ —Å–∞–º—ã–π –∫–æ–Ω–µ—Ü
    if video_path and os.path.exists(video_path):
        logging.info(f"üì¶ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ –≤ –∫–æ–Ω–µ—Ü –æ—á–µ—Ä–µ–¥–∏: {video_path}")
        key = "video_main"
        with open(video_path, 'rb') as f:
            files_to_send[key] = ("video.mp4", f.read(), "video/mp4")
        all_items.append({"type": "video", "media": f"attach://{key}"})

    if not all_items:
        logging.warning("‚ö†Ô∏è –ù–µ—Ç –º–µ–¥–∏–∞-—Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏.")
        return False

    # –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —á–∞–Ω–∫–∏ (–ø–æ 10 –æ–±—ä–µ–∫—Ç–æ–≤)
    total_items = len(all_items)
    chunks = [all_media_slice := all_items[i:i + 10] for i in range(0, total_items, 10)]
    url = f"https://api.telegram.org/bot{token}/sendMediaGroup"

    logging.info(f"üì§ –í—Å–µ–≥–æ –æ–±—ä–µ–∫—Ç–æ–≤: {total_items}. –ë—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {len(chunks)} –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø.")

    success = True
    for i, chunk in enumerate(chunks):
        current_files = {}
        for item in chunk:
            key = item["media"].replace("attach://", "")
            if key in files_to_send:
                current_files[key] = files_to_send[key]
        
        data = {"chat_id": chat_id, "media": json.dumps(chunk)}
        
        logging.info(f"   üöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –≥—Ä—É–ø–ø—ã {i+1}/{len(chunks)}...")
        if not await _post_with_retry(client, "POST", url, data, current_files):
            logging.error(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≥—Ä—É–ø–ø—ã {i+1}")
            success = False
        
        await asyncio.sleep(1.5) # –ó–∞—â–∏—Ç–∞ –æ—Ç —Ñ–ª—É–¥–∞
        
    return success

async def send_message(client: httpx.AsyncClient, token: str, chat_id: str, text: str, **kwargs) -> bool:
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    data = {"chat_id": chat_id, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True}
    if kwargs.get("reply_markup"):
        data["reply_markup"] = json.dumps(kwargs["reply_markup"])
    return await _post_with_retry(client, "POST", url, data)

# --- –õ–û–ì–ò–ö–ê –°–û–°–¢–û–Ø–ù–ò–Ø ---

def load_posted_ids(state_file: Path) -> List[str]:
    if not state_file.is_file(): return []
    try:
        data = json.loads(state_file.read_text(encoding="utf-8"))
        if len(data) > MAX_POSTED_RECORDS: data = data[-MAX_POSTED_RECORDS:]
        return [str(item) for item in data if item is not None]
    except Exception: return []

def save_posted_ids(ids_to_save: List[str], state_file: Path) -> None:
    state_file.parent.mkdir(parents=True, exist_ok=True)
    try:
        final_ids = [int(i) for i in ids_to_save]
        with state_file.open("w", encoding="utf-8") as f:
            json.dump(final_ids, f, ensure_ascii=False, indent=2)
    except Exception as e: logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}")

# --- MAIN ---

async def main(parsed_dir: str, state_path: str, limit: Optional[int], watermark_scale: float):
    token, chat_id = os.getenv("TELEGRAM_TOKEN"), os.getenv("TELEGRAM_CHANNEL")
    parsed_root, state_file = Path(parsed_dir), Path(state_path)
    
    # 1. –ó–ê–ì–†–£–ó–ö–ê –ò–°–¢–û–†–ò–ò (–°—Ç—Ä–æ–≥–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å —Ç–∏–ø–æ–≤)
    posted_ids = []
    if state_file.is_file():
        try:
            raw_data = json.loads(state_file.read_text())
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –≤—Å—ë –≤ —Å—Ç—Ä–æ–∫–∏, —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
            posted_ids = [str(x) for x in raw_data if x is not None]
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ {state_path}: {e}")
            
    posted_set = set(posted_ids)
    logging.info(f"üìú –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è: {len(posted_set)} –æ–±—ä–µ–∫—Ç–æ–≤. (–§–∞–π–ª: {state_path})")

    # 2. –ü–û–ò–°–ö –ü–ê–ü–û–ö (–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π)
    if not parsed_root.exists():
        logging.error(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º '{parsed_dir}' –ù–ï –ù–ê–ô–î–ï–ù–ê!")
        return

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø–æ–¥–ø–∞–ø–∫–∏
    all_folders = [d for d in parsed_root.iterdir() if d.is_dir()]
    logging.info(f"üìÇ –í—Å–µ–≥–æ –ø–∞–ø–æ–∫ –≤ '{parsed_dir}': {len(all_folders)}")

    articles_to_post = []
    for d in sorted(all_folders, key=lambda x: x.name):
        meta_file = d / "meta.json"
        
        if not meta_file.is_file():
            logging.info(f"  üîç –ü–∞–ø–∫–∞ {d.name}: –ø—Ä–æ–ø—É—Å–∫ (–Ω–µ—Ç meta.json)")
            continue
            
        try:
            meta = json.loads(meta_file.read_text(encoding="utf-8"))
            aid = str(meta.get("id"))
            
            # –ì–õ–ê–í–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê
            if aid in posted_set:
                logging.info(f"  üîç ID {aid}: –ø—Ä–æ–ø—É—Å–∫ (—É–∂–µ –µ—Å—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏–∏)")
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ–∫—Å—Ç–∞
            text_file = meta.get("text_file", "")
            text_path = d / text_file
            if not text_path.is_file():
                logging.warning(f"  üîç ID {aid}: –ø—Ä–æ–ø—É—Å–∫ (—Ñ–∞–π–ª —Ç–µ–∫—Å—Ç–∞ {text_file} –Ω–µ –Ω–∞–π–¥–µ–Ω)")
                continue
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ñ–æ—Ç–æ
            img_dir = d / "images"
            imgs = sorted([p for p in img_dir.iterdir() if p.suffix.lower() in {".jpg", ".jpeg", ".png"}]) if img_dir.is_dir() else []
            
            articles_to_post.append({
                "id": aid, 
                "title": meta.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"), 
                "text_path": text_path, 
                "image_paths": imgs, 
                "video_url": meta.get("video_url")
            })
            logging.info(f"  ‚≠êÔ∏è ID {aid}: –î–û–ë–ê–í–õ–ï–ù –í –û–ß–ï–†–ï–î–¨ ({len(imgs)} —Ñ–æ—Ç–æ, –≤–∏–¥–µ–æ: {'–¥–∞' if meta.get('video_url') else '–Ω–µ—Ç'})")

        except Exception as e:
            logging.error(f"  ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ {d.name}: {e}")

    # 3. –ü–£–ë–õ–ò–ö–ê–¶–ò–Ø
    if not articles_to_post:
        logging.info("üîç –ù–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–µ –Ω–∞—à–ª–æ—Å—å.")
        return

    logging.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏—é {len(articles_to_post)} —Å—Ç–∞—Ç–µ–π...")

    async with httpx.AsyncClient() as client:
        sent_count = 0
        for article in articles_to_post:
            if limit and sent_count >= limit:
                logging.info(f"üõë –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {limit} —Å—Ç.")
                break
            
            logging.info(f"‚ñ∂Ô∏è –ü—É–±–ª–∏–∫—É–µ–º {article['id']}...")
            processed_video = None
            try:
                # –í–∏–¥–µ–æ
                if article["video_url"]:
                    processed_video = await process_video_logic(article["video_url"])

                # –ú–µ–¥–∏–∞ (—Ñ–æ—Ç–æ + –≤–∏–¥–µ–æ –≤ –∫–æ–Ω—Ü–µ)
                # –í—ã–∑—ã–≤–∞–µ–º —Ç–≤–æ—é —Ñ—É–Ω–∫—Ü–∏—é send_complex_media_group
                media_success = await send_complex_media_group(
                    client, token, chat_id, 
                    article["image_paths"], 
                    processed_video, 
                    watermark_scale
                )

                # –¢–µ–∫—Å—Ç (–≤—Å–µ–≥–¥–∞ —à–ª–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ –∏–ª–∏ –∫–∞–∫ –ø–æ–¥–ø–∏—Å—å, –µ—Å–ª–∏ –º–µ–¥–∏–∞ –Ω–µ —É—à–ª–æ)
                raw_text = article["text_path"].read_text(encoding="utf-8")
                # –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –æ–Ω —Ç–∞–º –µ—Å—Ç—å
                clean_body = raw_text
                if article['title'] in raw_text[:200]:
                    clean_body = raw_text.replace(article['title'], '', 1).strip()

                full_html = f"<b>{escape_html(article['title'])}</b>\n\n{escape_html(clean_body)}"
                chunks = chunk_text(full_html)

                for i, chunk in enumerate(chunks):
                    # –ö–Ω–æ–ø–∫–∏ —Ç–æ–ª—å–∫–æ –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∫—É—Å–∫—É
                    markup = None
                    if i == len(chunks) - 1:
                        markup = {"inline_keyboard": [[{"text": "–û–±–º–µ–Ω", "url": "https://t.me/mister1dollar"}]]}
                    
                    await send_message(client, token, chat_id, chunk, reply_markup=markup)

                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É—Å–ø–µ—Ö
                posted_ids.append(article['id'])
                sent_count += 1
                logging.info(f"‚úÖ ID {article['id']} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")

            except Exception as e:
                logging.error(f"‚ùå –ü—Ä–æ–≤–∞–ª –Ω–∞ ID {article['id']}: {e}")
            finally:
                if processed_video and os.path.exists(processed_video):
                    os.remove(processed_video)
            
            await asyncio.sleep(float(os.getenv("POST_DELAY", DEFAULT_DELAY)))

    # 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –°–û–°–¢–û–Ø–ù–ò–Ø
    if sent_count > 0:
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–≤–µ–∂–∏–µ –∑–∞–ø–∏—Å–∏
        new_history = [int(i) for i in posted_ids[-MAX_POSTED_RECORDS:]]
        state_file.write_text(json.dumps(new_history, indent=2))
        logging.info(f"üíæ –ò—Å—Ç–æ—Ä–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞: {state_path}")

    if sent_count > 0:
        if len(final_posted_ids) > MAX_POSTED_RECORDS:
            final_posted_ids = final_posted_ids[-MAX_POSTED_RECORDS:]
        save_posted_ids(final_posted_ids, state_file)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--parsed-dir", type=str, default="articles")
    parser.add_argument("--state-file", type=str, default="articles/posted.json")
    parser.add_argument("-n", "--limit", type=int, default=None)
    parser.add_argument("--watermark-scale", type=float, default=WATERMARK_SCALE)
    args = parser.parse_args()
    asyncio.run(main(args.parsed_dir, args.state_file, args.limit, args.watermark_scale))
