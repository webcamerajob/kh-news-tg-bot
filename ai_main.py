import os
import sys
import json
import logging
import time
import requests
import translators as ts  # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –æ–±—ã—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
import main  # –¢–≤–æ–π –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π main.py

# --- –°–ü–ò–°–û–ö –ú–û–î–ï–õ–ï–ô ---
# –ò—Å–ø–æ–ª—å–∑—É–µ–º Llama 3.3 –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é, –æ–Ω–∞ –æ—Ç–ª–∏—á–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç
AI_MODELS = [
    "meta-llama/llama-3.3-70b-instruct:free",
    "google/gemini-2.0-flash-exp:free",
    "deepseek/deepseek-r1-distill-llama-70b:free",
    "meta-llama/llama-3.2-3b-instruct:free",
]

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

# --- –§–£–ù–ö–¶–ò–Ø –û–ë–´–ß–ù–û–ì–û –ü–ï–†–ï–í–û–î–ê (–ì–£–ì–õ/–ë–ò–ù–ì) ---
def standard_translate(text: str, to_lang: str = "ru") -> str:
    """
    –ë–µ—Ä–µ—Ç —á–∏—Å—Ç—ã–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —Ç–µ–∫—Å—Ç –∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤.
    """
    if not text: return ""
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    providers = ["google", "bing", "yandex"]
    
    for provider in providers:
        try:
            # logging.info(f"   üåç –ü–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ {provider}...")
            # sleep —á—Ç–æ–±—ã –Ω–µ –±–∞–Ω–∏–ª–∏
            time.sleep(1) 
            result = ts.translate_text(
                query_text=text,
                translator=provider,
                from_language="en",
                to_language=to_lang,
                timeout=20
            )
            return result
        except Exception as e:
            # logging.warning(f"   ‚ö†Ô∏è {provider} –Ω–µ —Å–º–æ–≥: {e}")
            continue
            
    # –ï—Å–ª–∏ –Ω–∏–∫—Ç–æ –Ω–µ —Å–º–æ–≥ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–π (–ª—É—á—à–µ —á–µ–º –Ω–∏—á–µ–≥–æ)
    logging.error("‚ùå –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–µ—Ä–µ–≤–æ–¥–∞ –æ—Ç–∫–∞–∑–∞–ª–∏.")
    return text

# --- –§–£–ù–ö–¶–ò–Ø –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø ---
def format_paragraphs(text: str) -> str:
    """–î–µ–ª–∞–µ—Ç –¥–≤–æ–π–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –≤ Telegram."""
    paragraphs = [p.strip() for p in text.replace('\r', '').split('\n') if p.strip()]
    return "\n\n".join(paragraphs)

# --- –ì–õ–ê–í–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
def ai_clean_and_then_translate(text: str, to_lang: str = "ru", provider: str = "ai") -> str:
    if not text or not text.strip(): return ""
    
    # –ï—Å–ª–∏ –∫–ª—é—á–∞ –Ω–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –Ω–∞ –≥—Ä—è–∑–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
    if not OPENROUTER_API_KEY: 
        logging.warning("‚ö†Ô∏è [AI] –ö–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞.")
        return standard_translate(text, to_lang)

    # 1. –≠–¢–ê–ü –û–ß–ò–°–¢–ö–ò (–ò–ò)
    logging.info("‚è≥ –ü–∞—É–∑–∞ 5 —Å–µ–∫ –ø–µ—Ä–µ–¥ –ò–ò...")
    time.sleep(5) 
    logging.info(f"ü§ñ [AI] 1. –ß–∏—Å—Ç–∫–∞ –∏ —Å–∞–º–º–∞—Ä–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º...")

    # –ü—Ä–æ–º–ø—Ç: –ø—Ä–æ—Å–∏–º —Å–¥–µ–ª–∞—Ç—å —á–∏—Å—Ç–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ –ê–ù–ì–õ–ò–ô–°–ö–û–ú
    prompt = (
        f"You are a professional news editor.\n"
        f"TASK: Read the raw text below and write a CONCISE SUMMARY in ENGLISH.\n\n"
        "GUIDELINES:\n"
        "1. LANGUAGE: English only.\n"
        "2. CONTENT: Remove ads, 'Related Articles', links, and fluff.\n"
        "3. STYLE: Journalistic, objective, factual.\n"
        "4. STRUCTURE: Keep paragraphs clear.\n\n"
        f"RAW TEXT:\n{text[:15000]}"
    )

    clean_english_text = ""

    # –¶–∏–∫–ª –ø–æ –º–æ–¥–µ–ª—è–º
    for model in AI_MODELS:
        try:
            response = requests.post(
                url="https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://github.com/parser-bot",
                    "X-Title": "NewsBot",
                },
                data=json.dumps({
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.3 # –ü–æ–Ω–∏–∂–µ, —á—Ç–æ–±—ã –±—ã–ª–æ —á–µ—Ç–∫–æ
                }),
                timeout=55
            )

            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and result['choices']:
                    clean_english_text = result['choices'][0]['message']['content'].strip()
                    logging.info(f"‚úÖ [AI] –û—á–∏—Å—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞ ({model}).")
                    break # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –º–æ–¥–µ–ª–µ–π
            
            elif response.status_code == 429:
                logging.warning(f"‚ö†Ô∏è [AI] {model} (429). –ñ–¥–µ–º...")
                time.sleep(2)
            else:
                logging.warning(f"‚ö†Ô∏è [AI] {model} –æ—à–∏–±–∫–∞ {response.status_code}.")
        
        except Exception as e:
            logging.error(f"‚ö†Ô∏è [AI] –°–±–æ–π {model}: {e}")
            continue

    # –ï—Å–ª–∏ –ò–ò –Ω–µ —Å–ø—Ä–∞–≤–∏–ª—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–∞–∫ "—á–∏—Å—Ç—ã–π"
    if not clean_english_text:
        logging.error("‚ùå [AI] –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç. –ü–µ—Ä–µ–≤–æ–¥–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª.")
        clean_english_text = text

    # 2. –≠–¢–ê–ü –ü–ï–†–ï–í–û–î–ê (–ü–†–û–í–ê–ô–î–ï–†–´)
    logging.info(f"üåç [Translators] 2. –ü–µ—Ä–µ–≤–æ–¥ —á–∏—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–∏–π...")
    
    final_russian_text = standard_translate(clean_english_text, to_lang)
    
    # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    return format_paragraphs(final_russian_text)

# --- –ó–ê–ü–£–°–ö ---
if __name__ == "__main__":
    # –ü–æ–¥–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–µ—Ä–µ–≤–æ–¥–∞ –≤ main –Ω–∞ –Ω–∞—à—É –≥–∏–±—Ä–∏–¥–Ω—É—é
    main.translate_text = ai_clean_and_then_translate
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º
    main.main()
